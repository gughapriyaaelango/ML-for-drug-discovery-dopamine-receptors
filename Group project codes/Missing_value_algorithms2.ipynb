{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d1936bd8",
      "metadata": {
        "id": "d1936bd8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "0d2b1cc9",
      "metadata": {
        "id": "0d2b1cc9"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import missingno as msno\n",
        "from scipy.stats import chi2\n",
        "from impyute.imputation.cs import mice\n",
        "import statsmodels.api as sm\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer\n",
        "from sklearn import linear_model\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "from rdkit.Chem import Descriptors, Lipinski, Draw\n",
        "#from mordred import Calculator, descriptors\n",
        "#import joblib\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.layers import Input, Dense\n",
        "from keras.models import Model\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pz2VEYYHP1AG"
      },
      "id": "pz2VEYYHP1AG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JJ2lqGC9P-tc",
        "outputId": "b55c141d-2208-4f91-e32e-41b37bd3cc05"
      },
      "id": "JJ2lqGC9P-tc",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "aa2666c2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "aa2666c2",
        "outputId": "2ec865a6-9f0b-442a-aa9f-9c5c3843accf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  molecule_chembl_id                            canonical_smiles  \\\n",
              "0       CHEMBL133551       COCC1(c2ccc(Cl)cc2)c2ccccc2C2=NCCCN21   \n",
              "1       CHEMBL337609    COc1cc(C2(O)c3ccccc3C3=NCCN32)cc(OC)c1OC   \n",
              "2       CHEMBL336827    OC1(c2ccc(Cl)cc2)c2ccccc2-c2nc3ccccc3n21   \n",
              "3       CHEMBL441477  OC1(c2ccc(Cl)cc2)c2ccccc2C2=NCc3ccccc3CN21   \n",
              "4       CHEMBL131792   OC1(c2ccc(Cl)cc2)c2ccccc2C2=Nc3ccccc3CN21   \n",
              "\n",
              "  standard_type  standard_value standard_units       MW  HeavyAtomMolWt  \\\n",
              "0    Inhibition             5.0              %  326.827         307.675   \n",
              "1    Inhibition             5.7              %  340.379         320.219   \n",
              "2    Inhibition            30.0              %  332.790         319.686   \n",
              "3    Inhibition            12.0              %  360.844         343.708   \n",
              "4    Inhibition            45.0              %  346.817         331.697   \n",
              "\n",
              "     LogP     MolMR  NumHDonors  NumHAcceptors  NumAtoms   AR   TPSA   RB  \n",
              "0  3.6959   93.2770         0.0            3.0      23.0  2.0  24.83  3.0  \n",
              "1  1.9816   93.6488         1.0            6.0      25.0  2.0  63.52  4.0  \n",
              "2  4.4118   95.0178         1.0            3.0      24.0  4.0  38.05  1.0  \n",
              "3  4.3094  103.1188         1.0            3.0      26.0  3.0  35.83  1.0  \n",
              "4  4.4409   99.0748         1.0            3.0      25.0  3.0  35.83  1.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc42f7fc-55bf-4dd4-b0ea-c175bfd1921b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>molecule_chembl_id</th>\n",
              "      <th>canonical_smiles</th>\n",
              "      <th>standard_type</th>\n",
              "      <th>standard_value</th>\n",
              "      <th>standard_units</th>\n",
              "      <th>MW</th>\n",
              "      <th>HeavyAtomMolWt</th>\n",
              "      <th>LogP</th>\n",
              "      <th>MolMR</th>\n",
              "      <th>NumHDonors</th>\n",
              "      <th>NumHAcceptors</th>\n",
              "      <th>NumAtoms</th>\n",
              "      <th>AR</th>\n",
              "      <th>TPSA</th>\n",
              "      <th>RB</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CHEMBL133551</td>\n",
              "      <td>COCC1(c2ccc(Cl)cc2)c2ccccc2C2=NCCCN21</td>\n",
              "      <td>Inhibition</td>\n",
              "      <td>5.0</td>\n",
              "      <td>%</td>\n",
              "      <td>326.827</td>\n",
              "      <td>307.675</td>\n",
              "      <td>3.6959</td>\n",
              "      <td>93.2770</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>23.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>24.83</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>CHEMBL337609</td>\n",
              "      <td>COc1cc(C2(O)c3ccccc3C3=NCCN32)cc(OC)c1OC</td>\n",
              "      <td>Inhibition</td>\n",
              "      <td>5.7</td>\n",
              "      <td>%</td>\n",
              "      <td>340.379</td>\n",
              "      <td>320.219</td>\n",
              "      <td>1.9816</td>\n",
              "      <td>93.6488</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>63.52</td>\n",
              "      <td>4.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CHEMBL336827</td>\n",
              "      <td>OC1(c2ccc(Cl)cc2)c2ccccc2-c2nc3ccccc3n21</td>\n",
              "      <td>Inhibition</td>\n",
              "      <td>30.0</td>\n",
              "      <td>%</td>\n",
              "      <td>332.790</td>\n",
              "      <td>319.686</td>\n",
              "      <td>4.4118</td>\n",
              "      <td>95.0178</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>24.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>38.05</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>CHEMBL441477</td>\n",
              "      <td>OC1(c2ccc(Cl)cc2)c2ccccc2C2=NCc3ccccc3CN21</td>\n",
              "      <td>Inhibition</td>\n",
              "      <td>12.0</td>\n",
              "      <td>%</td>\n",
              "      <td>360.844</td>\n",
              "      <td>343.708</td>\n",
              "      <td>4.3094</td>\n",
              "      <td>103.1188</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>26.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35.83</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CHEMBL131792</td>\n",
              "      <td>OC1(c2ccc(Cl)cc2)c2ccccc2C2=Nc3ccccc3CN21</td>\n",
              "      <td>Inhibition</td>\n",
              "      <td>45.0</td>\n",
              "      <td>%</td>\n",
              "      <td>346.817</td>\n",
              "      <td>331.697</td>\n",
              "      <td>4.4409</td>\n",
              "      <td>99.0748</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>25.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35.83</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc42f7fc-55bf-4dd4-b0ea-c175bfd1921b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc42f7fc-55bf-4dd4-b0ea-c175bfd1921b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc42f7fc-55bf-4dd4-b0ea-c175bfd1921b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/AML Group/missing_data.csv\")\n",
        "data.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5d852960",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5d852960",
        "outputId": "54e314c4-1d6f-4896-87da-5ae9222d75fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "207405c5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "207405c5",
        "outputId": "ca631c76-13f9-4c11-fd4c-5411a918a709"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1258, 11)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "data_impute=data[[\"standard_value\",\"MW\",\"HeavyAtomMolWt\",\"LogP\",\"MolMR\",\"NumHDonors\",\"NumHAcceptors\",\"NumAtoms\",\"AR\",\"TPSA\",\"RB\"]]\n",
        "data_impute.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "46d9ee52",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46d9ee52",
        "outputId": "67dbbbbd-0466-4511-b9e0-469ff4684e8a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "standard_value    175\n",
              "MW                  0\n",
              "HeavyAtomMolWt      0\n",
              "LogP                0\n",
              "MolMR               0\n",
              "NumHDonors          0\n",
              "NumHAcceptors       0\n",
              "NumAtoms            0\n",
              "AR                  0\n",
              "TPSA                0\n",
              "RB                  0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "data_impute.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e24d9e9c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e24d9e9c",
        "outputId": "eeefdd04-f466-420d-a6d0-f79a4c1c989e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average training error: 3527.3132496545395\n",
            "Average validation error: 5249.701339406072\n"
          ]
        }
      ],
      "source": [
        "#MICE ALGORITHM WITH K-FOLD CROSS VALIDATION\n",
        "#Finding training and validation loss using MICE\n",
        "mice_imputer=IterativeImputer()\n",
        "n_folds = 10\n",
        "#cross validation object\n",
        "kf = KFold(n_splits=n_folds, shuffle=True)\n",
        "#training error list\n",
        "train_errors = np.zeros(n_folds)\n",
        "#validation error list\n",
        "val_errors = np.zeros(n_folds)\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(kf.split(data_impute)):\n",
        "    # split data into training and validation sets\n",
        "    train_df = data_impute.iloc[train_index]\n",
        "    val_df = data_impute.iloc[val_index]\n",
        "\n",
        "    # impute missing values using MICE on training set\n",
        "    train_imputed_array = mice_imputer.fit_transform(train_df)\n",
        "    train_imputed_df = pd.DataFrame(train_imputed_array, columns=train_df.columns)\n",
        "\n",
        "    # calculate training error\n",
        "    train_error = ((train_df - train_imputed_df) ** 2).mean().mean()\n",
        "    train_errors[i] = train_error\n",
        "\n",
        "    # impute missing values using MICE on validation set\n",
        "    val_imputed_array = mice_imputer.transform(val_df)\n",
        "    val_imputed_df = pd.DataFrame(val_imputed_array, columns=val_df.columns)\n",
        "\n",
        "    # calculate validation error\n",
        "    val_error = ((val_df - val_imputed_df) ** 2).mean().mean()\n",
        "    val_errors[i] = val_error\n",
        "\n",
        "\n",
        "print(\"Average training error:\", train_errors.mean())\n",
        "print(\"Average validation error:\", val_errors.mean())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "fb07a39e",
      "metadata": {
        "id": "fb07a39e"
      },
      "outputs": [],
      "source": [
        "#MICE ALGORITHM - imputing\n",
        "mice_imputer=IterativeImputer()\n",
        "imputed_array = mice_imputer.fit_transform(data_impute)\n",
        "imputed_df = pd.DataFrame(imputed_array, columns=data_impute.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "414786d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "414786d6",
        "outputId": "abbcaa5d-ef1a-4e3a-898e-5bfd6b91d932"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "missing in inh 0\n"
          ]
        }
      ],
      "source": [
        "print(\"missing in inh\",imputed_df.standard_value.isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "a9297053",
      "metadata": {
        "id": "a9297053"
      },
      "outputs": [],
      "source": [
        "#Midas\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_df = data_impute.sample(frac=0.8, random_state=1)\n",
        "val_df = data_impute.drop(train_df.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "c144d070",
      "metadata": {
        "id": "c144d070"
      },
      "outputs": [],
      "source": [
        "def midas_impute(df, k):\n",
        "    \"\"\"\n",
        "    Implements the MIDAS algorithm for imputing missing values in a dataframe\n",
        "    \n",
        "    Parameters:\n",
        "        df (pandas dataframe): The input dataframe to impute missing values in\n",
        "        k (int): The number of previous time steps to use for imputation\n",
        "        \n",
        "    Returns:\n",
        "        imputed_df (pandas dataframe): The imputed dataframe\n",
        "    \"\"\"\n",
        "    \n",
        "    # Create a copy of the input dataframe to store the imputed values\n",
        "    imputed_df = df.copy()\n",
        "    \n",
        "    # Loop through each column in the dataframe\n",
        "    for col in df.columns:\n",
        "        \n",
        "        # Check if the column has any missing values\n",
        "        if df[col].isnull().sum() > 0:\n",
        "            \n",
        "            # Loop through each row in the dataframe\n",
        "            for i in range(df.shape[0]):\n",
        "                \n",
        "                # Check if the value in the current row is missing\n",
        "                if pd.isnull(df.loc[i, col]):\n",
        "                    \n",
        "                    # Calculate the start and end indices for the previous time steps\n",
        "                    start_idx = max(0, i - k)\n",
        "                    end_idx = i\n",
        "                    \n",
        "                    # Calculate the weighted average of the previous time steps\n",
        "                    weights = np.arange(1, end_idx - start_idx + 2)\n",
        "                    imputed_df.loc[i, col] = np.sum(df.loc[start_idx:end_idx, col] * weights) / np.sum(weights)\n",
        "    \n",
        "    return imputed_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d79e66bf",
      "metadata": {
        "scrolled": true,
        "id": "d79e66bf"
      },
      "outputs": [],
      "source": [
        "# Impute missing values in the training set\n",
        "train_imputed_df = midas_impute(train_df, k=3)\n",
        "\n",
        "# Impute missing values in the validation set\n",
        "val_imputed_df = midas_impute(val_df, k=3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0f55a843",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f55a843",
        "outputId": "bb8546fa-2cdf-4658-c105-3f0911e8a37e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: standard_value     1997.746102\n",
            "MW                14972.462382\n",
            "HeavyAtomMolWt    14070.032164\n",
            "LogP                  3.715834\n",
            "MolMR               882.639516\n",
            "NumHDonors            2.343202\n",
            "NumHAcceptors         7.612939\n",
            "NumAtoms             66.729167\n",
            "AR                    1.201754\n",
            "TPSA               2891.682200\n",
            "RB                    9.702851\n",
            "dtype: float64\n",
            "Validation MSE: standard_value     3153.357659\n",
            "MW                18593.179650\n",
            "HeavyAtomMolWt    18265.661357\n",
            "LogP                  2.825693\n",
            "MolMR               788.719822\n",
            "NumHDonors            3.000000\n",
            "NumHAcceptors        11.058824\n",
            "NumAtoms             68.235294\n",
            "AR                    1.352941\n",
            "TPSA               3588.522459\n",
            "RB                    6.882353\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n",
            "/usr/local/lib/python3.9/dist-packages/numpy/core/fromnumeric.py:3472: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Calculate the mean squared error for the training set\n",
        "train_mse = np.mean((train_imputed_df - train_df)**2)\n",
        "print(\"Training MSE:\", train_mse)\n",
        "\n",
        "# Calculate the mean squared error for the validation set\n",
        "val_mse = np.mean((val_imputed_df - val_df)**2)\n",
        "print(\"Validation MSE:\", val_mse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "55072bd3",
      "metadata": {
        "id": "55072bd3"
      },
      "outputs": [],
      "source": [
        "#Softimpute\n",
        "train_df, val_df = train_test_split(data_impute, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "3380d33c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3380d33c",
        "outputId": "a8153b3a-cf0a-4cbd-efaa-d6ccd5f8394a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SoftImpute] Max Singular Value of X_init = 17619.333117\n",
            "[SoftImpute] Iter 1: observed MAE=4.025245 rank=3\n",
            "[SoftImpute] Iter 2: observed MAE=4.041673 rank=3\n",
            "[SoftImpute] Iter 3: observed MAE=4.051817 rank=3\n",
            "[SoftImpute] Iter 4: observed MAE=4.057797 rank=3\n",
            "[SoftImpute] Iter 5: observed MAE=4.061322 rank=3\n",
            "[SoftImpute] Iter 6: observed MAE=4.063550 rank=3\n",
            "[SoftImpute] Iter 7: observed MAE=4.064941 rank=3\n",
            "[SoftImpute] Iter 8: observed MAE=4.065811 rank=3\n",
            "[SoftImpute] Iter 9: observed MAE=4.066372 rank=3\n",
            "[SoftImpute] Iter 10: observed MAE=4.066742 rank=3\n",
            "[SoftImpute] Iter 11: observed MAE=4.066990 rank=3\n",
            "[SoftImpute] Iter 12: observed MAE=4.067159 rank=3\n",
            "[SoftImpute] Iter 13: observed MAE=4.067274 rank=3\n",
            "[SoftImpute] Iter 14: observed MAE=4.067355 rank=3\n",
            "[SoftImpute] Iter 15: observed MAE=4.067411 rank=3\n",
            "[SoftImpute] Iter 16: observed MAE=4.067450 rank=3\n",
            "[SoftImpute] Iter 17: observed MAE=4.067478 rank=3\n",
            "[SoftImpute] Iter 18: observed MAE=4.067498 rank=3\n",
            "[SoftImpute] Iter 19: observed MAE=4.067512 rank=3\n",
            "[SoftImpute] Stopped after iteration 19 for lambda=352.386662\n",
            "[SoftImpute] Max Singular Value of X_init = 8532.594697\n",
            "[SoftImpute] Iter 1: observed MAE=4.010576 rank=3\n",
            "[SoftImpute] Iter 2: observed MAE=4.022516 rank=3\n",
            "[SoftImpute] Iter 3: observed MAE=4.029777 rank=3\n",
            "[SoftImpute] Iter 4: observed MAE=4.034286 rank=3\n",
            "[SoftImpute] Iter 5: observed MAE=4.036997 rank=3\n",
            "[SoftImpute] Iter 6: observed MAE=4.038659 rank=3\n",
            "[SoftImpute] Iter 7: observed MAE=4.039718 rank=3\n",
            "[SoftImpute] Iter 8: observed MAE=4.040408 rank=3\n",
            "[SoftImpute] Iter 9: observed MAE=4.040871 rank=3\n",
            "[SoftImpute] Iter 10: observed MAE=4.041185 rank=3\n",
            "[SoftImpute] Iter 11: observed MAE=4.041403 rank=3\n",
            "[SoftImpute] Iter 12: observed MAE=4.041557 rank=3\n",
            "[SoftImpute] Iter 13: observed MAE=4.041667 rank=3\n",
            "[SoftImpute] Iter 14: observed MAE=4.041747 rank=3\n",
            "[SoftImpute] Iter 15: observed MAE=4.041807 rank=3\n",
            "[SoftImpute] Iter 16: observed MAE=4.041850 rank=3\n",
            "[SoftImpute] Iter 17: observed MAE=4.041882 rank=3\n",
            "[SoftImpute] Iter 18: observed MAE=4.041905 rank=3\n",
            "[SoftImpute] Iter 19: observed MAE=4.041922 rank=3\n",
            "[SoftImpute] Iter 20: observed MAE=4.041934 rank=3\n",
            "[SoftImpute] Stopped after iteration 20 for lambda=170.651894\n"
          ]
        }
      ],
      "source": [
        "from fancyimpute import SoftImpute\n",
        "\n",
        "# assume 'train_df' and 'val_df' are the split dataframes\n",
        "train_df_imputed = SoftImpute().fit_transform(train_df)\n",
        "val_df_imputed = SoftImpute().fit_transform(val_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "51a18d9a",
      "metadata": {
        "id": "51a18d9a"
      },
      "outputs": [],
      "source": [
        "#DAE\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Split data into train and validation sets (80/20 split)\n",
        "train_data, val_data = train_test_split(data_impute, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "cdae5cd6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdae5cd6",
        "outputId": "c0bebf4e-4a98-4929-c3d4-63ef4d51faac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "32/32 [==============================] - 1s 9ms/step - loss: nan - val_loss: nan\n",
            "Epoch 2/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 3/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 4/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 5/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 6/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 7/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 8/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 9/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 10/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 11/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 12/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 13/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 14/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 15/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 16/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 17/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 18/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 19/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 20/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 21/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 22/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 23/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 24/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 25/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 26/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 27/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 28/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 29/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 30/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 31/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 32/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 33/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 34/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 35/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 36/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 37/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 38/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 39/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 40/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 41/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 42/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 43/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 44/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 45/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 46/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 47/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 48/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 49/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 50/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 51/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 52/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 53/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 54/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 55/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 56/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 57/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 58/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 59/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 60/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 61/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 62/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 63/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 64/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 65/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 66/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 67/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 68/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 69/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 70/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 71/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 72/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 73/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 74/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 75/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 76/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 77/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 78/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 79/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 80/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 81/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 82/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 83/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 84/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 85/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 86/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 87/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 88/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 89/100\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan - val_loss: nan\n",
            "Epoch 90/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 91/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 92/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 93/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 94/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 95/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 96/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 97/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 98/100\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan - val_loss: nan\n",
            "Epoch 99/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n",
            "Epoch 100/100\n",
            "32/32 [==============================] - 0s 5ms/step - loss: nan - val_loss: nan\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe2ff05adf0>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "#DAE\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler()\n",
        "train_data_scaled = scaler.fit_transform(train_data)\n",
        "val_data_scaled = scaler.transform(val_data)\n",
        "\n",
        "# Create the DAE model\n",
        "input_layer = Input(shape=(train_data.shape[1],))\n",
        "encoded = Dense(32, activation='relu')(input_layer)\n",
        "decoded = Dense(train_data.shape[1], activation='sigmoid')(encoded)\n",
        "dae = Model(input_layer, decoded)\n",
        "\n",
        "# Compile the DAE model\n",
        "dae.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "\n",
        "# Train the DAE model\n",
        "dae.fit(train_data_scaled, train_data_scaled, epochs=100, batch_size=32, validation_data=(val_data_scaled, val_data_scaled))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "6b54e696",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6b54e696",
        "outputId": "2265e4e5-386a-4c8d-d82f-c7c046a8f7d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32/32 [==============================] - 0s 5ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n"
          ]
        }
      ],
      "source": [
        "# Impute missing values in the training and validation sets\n",
        "train_data_imputed = dae.predict(train_data_scaled)\n",
        "val_data_imputed = dae.predict(val_data_scaled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "0b4078bf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0b4078bf",
        "outputId": "e18e42e6-5ad4-45a0-b901-3cd64279259f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training error: nan\n",
            "Validation error: nan\n"
          ]
        }
      ],
      "source": [
        "# Compute the training and validation errors\n",
        "train_error = np.mean(np.abs(train_data_scaled - train_data_imputed))\n",
        "val_error = np.mean(np.abs(val_data_scaled - val_data_imputed))\n",
        "\n",
        "print(f'Training error: {train_error:.4f}')\n",
        "print(f'Validation error: {val_error:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "5a0fc910",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5a0fc910",
        "outputId": "c889b35e-2b37-4b4b-fe9a-05dc501801d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "32/32 [==============================] - 2s 7ms/step - loss: nan\n",
            "Epoch 2/10\n",
            "32/32 [==============================] - 0s 6ms/step - loss: nan\n",
            "Epoch 3/10\n",
            "32/32 [==============================] - 0s 7ms/step - loss: nan\n",
            "Epoch 4/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 5/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 6/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 7/10\n",
            "32/32 [==============================] - 0s 4ms/step - loss: nan\n",
            "Epoch 8/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 9/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan\n",
            "Epoch 10/10\n",
            "32/32 [==============================] - 0s 3ms/step - loss: nan\n",
            "32/32 [==============================] - 0s 6ms/step\n",
            "8/8 [==============================] - 0s 4ms/step\n",
            "Training error: nan\n",
            "Validation error: nan\n"
          ]
        }
      ],
      "source": [
        "#AE\n",
        "# Step 1: Split data into train and validation sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train_data, val_data = train_test_split(data_impute, test_size=0.2, random_state=42)\n",
        "\n",
        "# Step 2: Impute missing values using AE\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "\n",
        "# Define the AE model\n",
        "input_dim = train_data.shape[1]\n",
        "encoding_dim = 64\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoder_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
        "decoder_layer = Dense(input_dim, activation='sigmoid')(encoder_layer)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder_layer)\n",
        "\n",
        "# Compile and fit the AE model only on non-missing data from train set\n",
        "autoencoder.compile(optimizer='adam', loss='mse')\n",
        "autoencoder.fit(train_data[train_data.notnull()], train_data[train_data.notnull()], epochs=10, batch_size=32)\n",
        "\n",
        "# Step 3: Compute imputed values for missing data in train and validation sets\n",
        "train_data_imputed = autoencoder.predict(train_data)\n",
        "val_data_imputed = autoencoder.predict(val_data)\n",
        "\n",
        "# Step 4: Compute reconstruction error for train and validation sets\n",
        "import numpy as np\n",
        "\n",
        "# Compute MSE for train set\n",
        "mse_train = np.mean(np.power(train_data - train_data_imputed, 2), axis=1)\n",
        "\n",
        "# Compute MSE for validation set\n",
        "mse_val = np.mean(np.power(val_data - val_data_imputed, 2), axis=1)\n",
        "\n",
        "# Step 5: Print MSE for train and validation sets\n",
        "print('Training error:', np.mean(mse_train))\n",
        "print('Validation error:', np.mean(mse_val))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}